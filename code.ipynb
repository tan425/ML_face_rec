{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'D:\\\\ML_face_rec'\n",
    "train_small_dir = os.path.join(data_dir, 'train')\n",
    "label_file = os.path.join(data_dir, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "class CustomImageFolder(Dataset):\n",
    "    def __init__(self, data_dir, label_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.label_file = pd.read_csv(label_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_file)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.label_file.iloc[idx, 1])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.label_file.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        label = class_names.index(label)\n",
    "        return image, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = os.path.join(self.data_dir, self.label_file.iloc[idx, 1])\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            label = self.label_file.iloc[idx, 2]\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            label = class_names.index(label)  \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {self.label_file.iloc[idx, 1]}, {e}\")\n",
    "\n",
    "            return torch.zeros(3, 224, 224), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomImageFolder(train_small_dir, label_file, transform=data_transforms['train'])\n",
    "val_dataset = CustomImageFolder(train_small_dir, label_file, transform=data_transforms['val'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = sorted(train_dataset.label_file['Category'].unique())\n",
    "if len(class_names) != 100:\n",
    "    raise ValueError(\"The number of unique categories in the CSV file should be 100.\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\123\\anaconda3\\envs\\ML_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\123\\anaconda3\\envs\\ML_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\123\\anaconda3\\envs\\ML_env\\lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "c:\\Users\\123\\anaconda3\\envs\\ML_env\\lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 4.5044, Val Loss: 4.3049, Val Accuracy: 0.0395\n",
      "Epoch 2/30, Train Loss: 4.1678, Val Loss: 3.9197, Val Accuracy: 0.0954\n",
      "Epoch 3/30, Train Loss: 3.9218, Val Loss: 3.7723, Val Accuracy: 0.1253\n",
      "Epoch 4/30, Train Loss: 3.7141, Val Loss: 3.3593, Val Accuracy: 0.2055\n",
      "Epoch 5/30, Train Loss: 3.5264, Val Loss: 3.2206, Val Accuracy: 0.2377\n",
      "Epoch 6/30, Train Loss: 3.3443, Val Loss: 3.0407, Val Accuracy: 0.2785\n",
      "Epoch 7/30, Train Loss: 3.1690, Val Loss: 2.7224, Val Accuracy: 0.3557\n",
      "Epoch 8/30, Train Loss: 3.0081, Val Loss: 2.6982, Val Accuracy: 0.3648\n",
      "Epoch 9/30, Train Loss: 2.8643, Val Loss: 2.3260, Val Accuracy: 0.4507\n",
      "Epoch 10/30, Train Loss: 2.7343, Val Loss: 2.2974, Val Accuracy: 0.4556\n",
      "Epoch 11/30, Train Loss: 2.6223, Val Loss: 2.0423, Val Accuracy: 0.5243\n",
      "Epoch 12/30, Train Loss: 2.5248, Val Loss: 2.0175, Val Accuracy: 0.5257\n",
      "Epoch 13/30, Train Loss: 2.4470, Val Loss: 2.2335, Val Accuracy: 0.4749\n",
      "Epoch 14/30, Train Loss: 2.3631, Val Loss: 1.8182, Val Accuracy: 0.5753\n",
      "Epoch 15/30, Train Loss: 2.2886, Val Loss: 1.6920, Val Accuracy: 0.6075\n",
      "Epoch 16/30, Train Loss: 2.2317, Val Loss: 1.6473, Val Accuracy: 0.6134\n",
      "Epoch 17/30, Train Loss: 2.1687, Val Loss: 1.5789, Val Accuracy: 0.6346\n",
      "Epoch 18/30, Train Loss: 2.1088, Val Loss: 1.5060, Val Accuracy: 0.6450\n",
      "Epoch 19/30, Train Loss: 2.0552, Val Loss: 1.4108, Val Accuracy: 0.6723\n",
      "Epoch 20/30, Train Loss: 2.0069, Val Loss: 1.3992, Val Accuracy: 0.6730\n",
      "Epoch 21/30, Train Loss: 1.9607, Val Loss: 1.3489, Val Accuracy: 0.6813\n",
      "Epoch 22/30, Train Loss: 1.9139, Val Loss: 1.3396, Val Accuracy: 0.6852\n",
      "Epoch 23/30, Train Loss: 1.8871, Val Loss: 1.2534, Val Accuracy: 0.7019\n",
      "Epoch 24/30, Train Loss: 1.8373, Val Loss: 1.1836, Val Accuracy: 0.7164\n",
      "Epoch 25/30, Train Loss: 1.8047, Val Loss: 1.1333, Val Accuracy: 0.7279\n",
      "Epoch 26/30, Train Loss: 1.7732, Val Loss: 1.1054, Val Accuracy: 0.7361\n",
      "Epoch 27/30, Train Loss: 1.7285, Val Loss: 1.1043, Val Accuracy: 0.7340\n",
      "Epoch 28/30, Train Loss: 1.7082, Val Loss: 1.0429, Val Accuracy: 0.7509\n",
      "Epoch 29/30, Train Loss: 1.6609, Val Loss: 0.9915, Val Accuracy: 0.7617\n",
      "Epoch 30/30, Train Loss: 1.6344, Val Loss: 0.9505, Val Accuracy: 0.7701\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to my device\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move to my device\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += (preds == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Val Accuracy: {val_correct/len(val_loader.dataset):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved at: D:\\ML_face_rec\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and generate submission file\n",
    "model.eval()\n",
    "predictions = []\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_files = sorted(os.listdir(test_dir))\n",
    "\n",
    "for file in test_files:\n",
    "    img_path = os.path.join(test_dir, file)\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = data_transforms['val'](image).unsqueeze(0).to(device, non_blocking=True)  # Move to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        predictions.append(class_names[pred.item()])\n",
    "\n",
    "submission_path = 'D:\\\\ML_face_rec\\\\submission.csv'\n",
    "submission = pd.DataFrame({'Id': test_files, 'Category': predictions})\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved at: {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved at: D:\\ML_face_rec\\submission_new1_epoch30.csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and generate submission file\n",
    "model.eval()\n",
    "predictions = []\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_files = sorted(os.listdir(test_dir))\n",
    "\n",
    "for file in test_files:\n",
    "    img_path = os.path.join(test_dir, file)\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    image = data_transforms['val'](image).unsqueeze(0).to(device, non_blocking=True)  # Move to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        predictions.append(class_names[pred.item()])\n",
    "\n",
    "submission_path = 'D:\\\\ML_face_rec\\\\submission_new1_epoch30.csv'\n",
    "file_names = [os.path.splitext(f)[0] for f in test_files] \n",
    "submission = pd.DataFrame({'Id': file_names, 'Category': predictions})\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved at: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
